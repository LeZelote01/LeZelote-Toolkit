"""
Conversational AI - Extension assistant CyberSec Toolkit Pro 2025 PORTABLE
Sprint 1.5 - IA conversationnelle avanc√©e pour interactions naturelles
"""
import asyncio
import json
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
from fastapi import HTTPException
from pydantic import BaseModel, Field

# Int√©gration Emergent LLM
try:
    from emergentintegrations import EmergentLLM
except ImportError:
    print("‚ö†Ô∏è EmergentLLM non disponible pour Conversational AI - Mode fallback activ√©")
    EmergentLLM = None

from backend.config import settings
from backend.database import get_collection

# Mod√®les de donn√©es Conversational AI
class ConversationContext(BaseModel):
    user_id: str = Field(..., description="ID utilisateur")
    session_id: str = Field(..., description="ID de session")
    conversation_type: str = Field("general", description="Type de conversation: general, support, training, consultation")
    user_profile: Optional[Dict[str, Any]] = Field(None, description="Profil utilisateur")
    preferences: Optional[Dict[str, Any]] = Field(None, description="Pr√©f√©rences utilisateur")

class ConversationMessage(BaseModel):
    message_id: str = Field(default_factory=lambda: str(uuid.uuid4()), description="ID unique du message")
    content: str = Field(..., description="Contenu du message")
    message_type: str = Field("text", description="Type de message: text, command, query, help")
    context: Optional[ConversationContext] = Field(None, description="Contexte de la conversation")
    attachments: Optional[List[Dict[str, Any]]] = Field(None, description="Fichiers ou donn√©es attach√©s")
    
class ConversationResponse(BaseModel):
    response_id: str = Field(default_factory=lambda: str(uuid.uuid4()), description="ID de la r√©ponse")
    content: str = Field(..., description="Contenu de la r√©ponse")
    response_type: str = Field("answer", description="Type de r√©ponse: answer, question, suggestion, command")
    confidence: float = Field(..., description="Niveau de confiance (0-1)")
    suggested_actions: Optional[List[str]] = Field(None, description="Actions sugg√©r√©es")
    follow_up_questions: Optional[List[str]] = Field(None, description="Questions de suivi")
    context_updated: bool = Field(False, description="Contexte mis √† jour")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))

class ConversationFlow(BaseModel):
    flow_id: str = Field(..., description="ID du flux de conversation")
    flow_name: str = Field(..., description="Nom du flux")
    description: str = Field(..., description="Description du flux")
    triggers: List[str] = Field(..., description="Mots-cl√©s ou phrases de d√©clenchement")
    steps: List[Dict[str, Any]] = Field(..., description="√âtapes du flux conversationnel")
    is_active: bool = Field(True, description="Flux actif")

class ConversationalAIService:
    """Service IA Conversationnelle - Interactions naturelles avanc√©es"""
    
    def __init__(self):
        self.llm_client = None
        self.conversation_flows = self._initialize_conversation_flows()
        self.active_conversations = {}  # Sessions actives
        self.conversation_history = {}  # Historique par utilisateur
        self.user_profiles = {}  # Profils utilisateur
        self._initialize_llm()
        
    def _initialize_llm(self):
        """Initialise le client LLM pour Conversational AI"""
        try:
            if EmergentLLM and settings.emergent_llm_key:
                self.llm_client = EmergentLLM(
                    api_key=settings.emergent_llm_key,
                    default_provider=settings.default_llm_provider,
                    default_model=settings.default_llm_model
                )
                print("‚úÖ Conversational AI initialis√© avec Emergent LLM")
            else:
                print("‚ö†Ô∏è Conversational AI - Mode simulation activ√©")
        except Exception as e:
            print(f"‚ùå Erreur initialisation Conversational AI LLM: {e}")
    
    def _initialize_conversation_flows(self) -> Dict[str, ConversationFlow]:
        """Initialise les flux de conversation pr√©d√©finis"""
        flows = {}
        
        # Flux 1: Onboarding S√©curit√©
        flows["security_onboarding"] = ConversationFlow(
            flow_id="security_onboarding",
            flow_name="Onboarding S√©curit√©",
            description="Guide l'utilisateur √† travers les fonctionnalit√©s de s√©curit√©",
            triggers=["aide", "help", "commencer", "guide", "onboarding"],
            steps=[
                {
                    "step": "welcome",
                    "message": "üëã Bienvenue dans CyberSec Toolkit Pro 2025! Je suis votre assistant IA sp√©cialis√© en cybers√©curit√©. Comment puis-je vous aider aujourd'hui?",
                    "options": ["D√©couvrir les services", "Faire un audit", "Configurer la s√©curit√©", "Formation"]
                },
                {
                    "step": "capability_intro",
                    "message": "üõ°Ô∏è Je peux vous aider avec 35 services cybers√©curit√© int√©gr√©s. Voulez-vous une d√©monstration sp√©cifique?",
                    "next_flows": ["pentest_demo", "incident_response_demo", "compliance_demo"]
                }
            ]
        )
        
        # Flux 2: D√©monstration Pentest
        flows["pentest_demo"] = ConversationFlow(
            flow_id="pentest_demo",
            flow_name="D√©monstration Pentesting",
            description="D√©montre les capacit√©s de tests de p√©n√©tration",
            triggers=["pentest", "test p√©n√©tration", "audit s√©curit√©", "vuln√©rabilit√©s"],
            steps=[
                {
                    "step": "pentest_intro",
                    "message": "üéØ Notre module Pentesting OWASP Top 10 peut analyser vos syst√®mes. Avez-vous une cible sp√©cifique √† tester?",
                    "collect_input": "target_system"
                },
                {
                    "step": "scan_options",
                    "message": "üìä Quel type de scan souhaitez-vous? 1) Scan rapide 2) Audit complet 3) Test personnalis√©",
                    "collect_input": "scan_type"
                },
                {
                    "step": "execute_scan",
                    "message": "‚ö° Lancement du scan... Cela peut prendre quelques minutes.",
                    "action": "trigger_pentest_scan"
                }
            ]
        )
        
        # Flux 3: Formation S√©curit√© Interactive
        flows["security_training"] = ConversationFlow(
            flow_id="security_training",
            flow_name="Formation S√©curit√© Interactive",
            description="Formation personnalis√©e en cybers√©curit√©",
            triggers=["formation", "apprendre", "training", "cours", "√©ducation"],
            steps=[
                {
                    "step": "assess_level",
                    "message": "üìö Quel est votre niveau en cybers√©curit√©? 1) D√©butant 2) Interm√©diaire 3) Avanc√©",
                    "collect_input": "security_level"
                },
                {
                    "step": "topic_selection",
                    "message": "üéØ Sur quoi voulez-vous vous former? OWASP, Incident Response, Compliance, Threat Intelligence?",
                    "collect_input": "training_topic"
                },
                {
                    "step": "personalized_content",
                    "message": "üìñ Voici un programme de formation personnalis√©...",
                    "action": "generate_training_content"
                }
            ]
        )
        
        # Flux 4: Support Technique
        flows["technical_support"] = ConversationFlow(
            flow_id="technical_support",
            flow_name="Support Technique",
            description="Assistance technique pour les probl√®mes",
            triggers=["probl√®me", "erreur", "bug", "support", "aide technique"],
            steps=[
                {
                    "step": "problem_identification",
                    "message": "üîß D√©crivez le probl√®me que vous rencontrez. Je vais vous aider √† le r√©soudre.",
                    "collect_input": "problem_description"
                },
                {
                    "step": "diagnostic",
                    "message": "üîç Analysons ce probl√®me ensemble...",
                    "action": "analyze_problem"
                },
                {
                    "step": "solution",
                    "message": "üí° Voici la solution recommand√©e...",
                    "action": "provide_solution"
                }
            ]
        )
        
        return flows
    
    async def process_message(self, message: ConversationMessage) -> ConversationResponse:
        """Traite un message conversationnel"""
        try:
            print(f"üí¨ Conversational AI - Traitement message: {message.content[:50]}...")
            
            # Analyse du contexte
            context = message.context or ConversationContext(
                user_id="anonymous",
                session_id=str(uuid.uuid4())
            )
            
            # Mise √† jour du profil utilisateur
            await self._update_user_profile(context.user_id, message)
            
            # D√©tection du type de conversation
            conversation_type = await self._detect_conversation_type(message.content)
            
            # V√©rification des flux conversationnels
            active_flow = await self._check_conversation_flows(message, context)
            
            if active_flow:
                # Traitement via flux conversationnel
                response = await self._process_conversation_flow(message, context, active_flow)
            else:
                # Traitement conversationnel libre
                response = await self._process_free_conversation(message, context)
            
            # Sauvegarde de la conversation
            await self._save_conversation_turn(context.user_id, context.session_id, message, response)
            
            return response
            
        except Exception as e:
            print(f"‚ùå Erreur traitement conversationnel: {e}")
            raise HTTPException(status_code=500, detail=f"Erreur Conversational AI: {str(e)}")
    
    async def _detect_conversation_type(self, message_content: str) -> str:
        """D√©tecte le type de conversation bas√© sur le contenu"""
        content_lower = message_content.lower()
        
        # Mots-cl√©s pour les diff√©rents types
        if any(word in content_lower for word in ["aide", "help", "comment", "guide"]):
            return "support"
        elif any(word in content_lower for word in ["apprendre", "formation", "cours", "expliquer"]):
            return "training"
        elif any(word in content_lower for word in ["scan", "audit", "pentest", "vuln√©rabilit√©"]):
            return "consultation"
        elif any(word in content_lower for word in ["probl√®me", "erreur", "bug", "marche pas"]):
            return "troubleshooting"
        else:
            return "general"
    
    async def _check_conversation_flows(self, message: ConversationMessage, context: ConversationContext) -> Optional[str]:
        """V√©rifie si le message d√©clenche un flux conversationnel"""
        content_lower = message.content.lower()
        
        for flow_id, flow in self.conversation_flows.items():
            for trigger in flow.triggers:
                if trigger.lower() in content_lower:
                    return flow_id
        
        # V√©rifier si l'utilisateur est dans un flux actif
        session_key = f"{context.user_id}_{context.session_id}"
        if session_key in self.active_conversations:
            return self.active_conversations[session_key].get("active_flow")
        
        return None
    
    async def _process_conversation_flow(self, message: ConversationMessage, 
                                       context: ConversationContext, flow_id: str) -> ConversationResponse:
        """Traite un message dans le cadre d'un flux conversationnel"""
        flow = self.conversation_flows[flow_id]
        session_key = f"{context.user_id}_{context.session_id}"
        
        # R√©cup√©rer ou initialiser l'√©tat du flux
        if session_key not in self.active_conversations:
            self.active_conversations[session_key] = {
                "active_flow": flow_id,
                "current_step": 0,
                "flow_data": {},
                "started_at": datetime.now(timezone.utc)
            }
        
        conversation_state = self.active_conversations[session_key]
        current_step_index = conversation_state["current_step"]
        
        if current_step_index >= len(flow.steps):
            # Flux termin√©
            del self.active_conversations[session_key]
            return ConversationResponse(
                content="‚úÖ Flux de conversation termin√©. Comment puis-je vous aider d'autre?",
                response_type="completion",
                confidence=0.9
            )
        
        current_step = flow.steps[current_step_index]
        
        # Traitement selon le type d'√©tape
        if "collect_input" in current_step:
            # Collecter l'entr√©e utilisateur
            input_key = current_step["collect_input"]
            conversation_state["flow_data"][input_key] = message.content
            
            # Passer √† l'√©tape suivante
            conversation_state["current_step"] += 1
            
            if conversation_state["current_step"] < len(flow.steps):
                next_step = flow.steps[conversation_state["current_step"]]
                response_content = next_step["message"]
            else:
                response_content = "‚úÖ Merci pour ces informations. Je traite votre demande..."
                # D√©clencher l'action finale si d√©finie
                if "action" in current_step:
                    action_result = await self._execute_flow_action(current_step["action"], conversation_state["flow_data"])
                    response_content += f"\n\n{action_result}"
        
        elif "action" in current_step:
            # Ex√©cuter une action
            action_result = await self._execute_flow_action(current_step["action"], conversation_state["flow_data"])
            response_content = current_step["message"] + f"\n\n{action_result}"
            conversation_state["current_step"] += 1
        
        else:
            # Message simple
            response_content = current_step["message"]
            conversation_state["current_step"] += 1
        
        # G√©n√©rer les actions sugg√©r√©es
        suggested_actions = current_step.get("options", [])
        follow_up = current_step.get("next_flows", [])
        
        return ConversationResponse(
            content=response_content,
            response_type="flow_step",
            confidence=0.9,
            suggested_actions=suggested_actions,
            follow_up_questions=[f"Voulez-vous en savoir plus sur {flow}?" for flow in follow_up[:3]],
            context_updated=True
        )
    
    async def _process_free_conversation(self, message: ConversationMessage, 
                                       context: ConversationContext) -> ConversationResponse:
        """Traite une conversation libre (sans flux d√©fini)"""
        if self.llm_client:
            return await self._process_llm_conversation(message, context)
        else:
            return await self._process_rule_based_conversation(message, context)
    
    async def _process_llm_conversation(self, message: ConversationMessage, 
                                      context: ConversationContext) -> ConversationResponse:
        """Traite la conversation via LLM"""
        try:
            # Construire le contexte pour le LLM
            system_prompt = self._build_conversation_system_prompt(context)
            conversation_history = await self._get_conversation_history(context.user_id, context.session_id)
            
            # Pr√©parer les messages
            messages = [{"role": "system", "content": system_prompt}]
            
            # Ajouter l'historique r√©cent
            for hist_msg in conversation_history[-5:]:  # Derniers 5 √©changes
                messages.append({"role": "user", "content": hist_msg.get("user_message", "")})
                messages.append({"role": "assistant", "content": hist_msg.get("assistant_response", "")})
            
            # Ajouter le message actuel
            messages.append({"role": "user", "content": message.content})
            
            # Appel LLM
            response = await asyncio.to_thread(
                self.llm_client.chat.completions.create,
                model=settings.default_llm_model,
                messages=messages,
                max_tokens=1200,
                temperature=0.7
            )
            
            response_content = response.choices[0].message.content
            
            # Analyser la r√©ponse pour extraire les actions sugg√©r√©es
            suggested_actions = self._extract_suggested_actions(response_content)
            follow_up_questions = self._extract_follow_up_questions(response_content)
            
            return ConversationResponse(
                content=response_content,
                response_type="llm_response",
                confidence=0.85,
                suggested_actions=suggested_actions,
                follow_up_questions=follow_up_questions
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur LLM conversationnel: {e}")
            return await self._process_rule_based_conversation(message, context)
    
    async def _process_rule_based_conversation(self, message: ConversationMessage, 
                                             context: ConversationContext) -> ConversationResponse:
        """Traite la conversation avec des r√®gles pr√©d√©finies"""
        content_lower = message.content.lower()
        
        # Patterns de r√©ponse bas√©s sur des r√®gles
        if any(word in content_lower for word in ["bonjour", "salut", "hello", "hi"]):
            response_content = """üëã **Bonjour et bienvenue dans CyberSec Toolkit Pro 2025 !**

Je suis votre assistant IA conversationnel sp√©cialis√© en cybers√©curit√©. Je peux vous aider avec :

üõ°Ô∏è **Services disponibles :**
‚Ä¢ Tests de p√©n√©tration automatis√©s
‚Ä¢ Analyse de conformit√© (ISO 27001, GDPR, NIST)
‚Ä¢ R√©ponse aux incidents en temps r√©el
‚Ä¢ Formation cybers√©curit√© interactive
‚Ä¢ Audit de s√©curit√© complet

üí¨ **Comment puis-je vous aider aujourd'hui ?**
Dites-moi simplement ce dont vous avez besoin !"""
            
            suggested_actions = ["Faire un scan de s√©curit√©", "Formation OWASP", "Aide technique", "D√©monstration"]
            
        elif any(word in content_lower for word in ["services", "fonctionnalit√©s", "capacit√©s"]):
            response_content = """üöÄ **CyberSec Toolkit Pro 2025 - 35 Services Int√©gr√©s**

**üõ°Ô∏è Services Cybers√©curit√© (11 op√©rationnels) :**
‚úÖ Assistant IA Expert ‚Ä¢ ‚úÖ Pentesting OWASP ‚Ä¢ ‚úÖ Incident Response
‚úÖ Digital Forensics ‚Ä¢ ‚úÖ Compliance ‚Ä¢ ‚úÖ Vulnerability Management
‚úÖ Monitoring 24/7 ‚Ä¢ ‚úÖ Threat Intelligence ‚Ä¢ ‚úÖ Red/Blue Team ‚Ä¢ ‚úÖ Audit

**üß† Services IA (6 en d√©veloppement Sprint 1.5) :**
üîÑ Cyber AI ‚Ä¢ üîÑ Predictive AI ‚Ä¢ üîÑ Automation AI
üîÑ Conversational AI ‚Ä¢ üîÑ Business AI ‚Ä¢ üîÑ Code Analysis AI

**üíº Services Business (5 planifi√©s) :**
üìã CRM ‚Ä¢ üìã Billing ‚Ä¢ üìã Analytics ‚Ä¢ üìã Planning ‚Ä¢ üìã Training

Sur quoi souhaitez-vous plus d'informations ?"""
            
            suggested_actions = ["Tester un service", "Voir les d√©mos", "Documentation technique"]
            
        elif any(word in content_lower for word in ["aide", "help", "comment"]):
            response_content = """‚ùì **Centre d'Aide CyberSec Toolkit Pro 2025**

Je peux vous assister sur :

**üîß Utilisation des outils :**
‚Ä¢ Configuration et param√©trage
‚Ä¢ Lancement d'analyses et scans
‚Ä¢ Interpr√©tation des r√©sultats

**üìö Formation et guidance :**
‚Ä¢ Meilleures pratiques cybers√©curit√©
‚Ä¢ Explication des concepts techniques
‚Ä¢ Recommandations personnalis√©es

**üö® Support technique :**
‚Ä¢ R√©solution de probl√®mes
‚Ä¢ Optimisation des performances
‚Ä¢ Questions sur les fonctionnalit√©s

Quelle est votre question sp√©cifique ?"""
            
            suggested_actions = ["Probl√®me technique", "Formation OWASP", "Configuration", "D√©monstration"]
            
        elif any(word in content_lower for word in ["pentest", "audit", "scan", "vuln√©rabilit√©"]):
            response_content = """üéØ **Module Pentesting & Audit OWASP Top 10**

Notre scanner professionnel peut analyser :

**üåê Applications Web :**
‚Ä¢ Injection SQL, XSS, CSRF
‚Ä¢ Broken Authentication
‚Ä¢ Security Misconfigurations
‚Ä¢ Vulnerable Components

**üîç Infrastructure :**
‚Ä¢ Scan de ports avanc√©
‚Ä¢ √ânum√©ration services
‚Ä¢ Tests configuration SSL/TLS
‚Ä¢ Headers de s√©curit√©

**üìä G√©n√©ration de rapports :**
‚Ä¢ PDF professionnel avec scoring CVSS
‚Ä¢ Recommandations prioris√©es
‚Ä¢ Plan de rem√©diation d√©taill√©

Voulez-vous lancer un scan de d√©monstration ?"""
            
            suggested_actions = ["Lancer scan d√©mo", "Plus d'infos OWASP", "Voir exemple rapport"]
            
        else:
            # R√©ponse g√©n√©rique
            response_content = f"""üí≠ **R√©ponse √† votre message :**

J'ai bien re√ßu votre message : "{message.content[:100]}{'...' if len(message.content) > 100 else ''}"

En tant qu'assistant IA cybers√©curit√©, je peux vous aider avec :
‚Ä¢ **Analyses techniques** - Scans, audits, tests
‚Ä¢ **Conseils experts** - Recommandations s√©curit√©
‚Ä¢ **Formation** - Explications et guides
‚Ä¢ **Support** - Assistance technique

Pouvez-vous √™tre plus pr√©cis sur votre besoin ?"""
            
            suggested_actions = ["Pr√©ciser ma demande", "Voir les services", "Aide g√©n√©rale"]
        
        return ConversationResponse(
            content=response_content,
            response_type="rule_based",
            confidence=0.7,
            suggested_actions=suggested_actions,
            follow_up_questions=["Avez-vous d'autres questions?", "Voulez-vous une d√©monstration?"]
        )
    
    def _build_conversation_system_prompt(self, context: ConversationContext) -> str:
        """Construit le prompt syst√®me pour la conversation"""
        base_prompt = """Tu es un assistant IA conversationnel expert en cybers√©curit√© pour CyberSec Toolkit Pro 2025.

üéØ TON R√îLE:
- Assistant conversationnel naturel et engageant
- Expert cybers√©curit√© avec 15+ ans d'exp√©rience
- Guide l'utilisateur √† travers les 35 services int√©gr√©s
- Fournit des r√©ponses personnalis√©es et actionnables

üí¨ STYLE CONVERSATIONNEL:
- Naturel et professionnel
- Utilise des emojis appropri√©s
- Questions de suivi pertinentes  
- Suggestions d'actions concr√®tes
- Adapt√© au niveau technique de l'utilisateur

üõ°Ô∏è SP√âCIALIT√âS:
- Tous les services CyberSec Toolkit Pro 2025
- Formation interactive cybers√©curit√©
- Support technique personnalis√©
- D√©monstrations guid√©es
- Conseils strat√©giques s√©curit√©"""
        
        # Personnalisation selon le contexte
        if context.conversation_type == "training":
            base_prompt += "\n\nüéì MODE FORMATION: Privil√©gie l'apprentissage progressif et les explications p√©dagogiques."
        elif context.conversation_type == "support":
            base_prompt += "\n\nüîß MODE SUPPORT: Focus sur la r√©solution rapide et efficace des probl√®mes."
        elif context.conversation_type == "consultation":
            base_prompt += "\n\nüíº MODE CONSULTATION: Approche strat√©gique et recommandations expertes."
        
        return base_prompt

    async def _update_user_profile(self, user_id: str, message: ConversationMessage) -> None:
        try:
            self.user_profiles.setdefault(user_id, {"messages": 0, "last_interaction": datetime.now(timezone.utc).isoformat()})
            self.user_profiles[user_id]["messages"] += 1
            self.user_profiles[user_id]["last_interaction"] = datetime.now(timezone.utc).isoformat()
        except Exception:
            pass

    async def _get_conversation_history(self, user_id: str, session_id: str) -> List[Dict[str, Any]]:
        try:
            key = f"{user_id}_{session_id}"
            return self.conversation_history.get(key, [])
        except Exception:
            return []

    async def _save_conversation_turn(self, user_id: str, session_id: str, message: ConversationMessage, response: ConversationResponse) -> None:
        try:
            key = f"{user_id}_{session_id}"
            self.conversation_history.setdefault(key, [])
            self.conversation_history[key].append({
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "user_message": message.content,
                "assistant_response": response.content,
                "response_type": response.response_type
            })
        except Exception:
            pass

    async def _execute_flow_action(self, action: str, data: Dict[str, Any]) -> str:
        try:
            if action == "trigger_pentest_scan":
                return "Scan de d√©monstration lanc√©. Vous recevrez un rapport synth√©tique."
            elif action == "generate_training_content":
                level = data.get("security_level", "interm√©diaire")
                topic = data.get("training_topic", "OWASP")
                return f"Contenu de formation {level} g√©n√©r√© pour le sujet {topic}."
            elif action == "analyze_problem":
                return "Diagnostic initial effectu√©. Probable probl√®me de configuration."
            elif action == "provide_solution":
                return "Solution propos√©e: red√©marrer le service et appliquer le patch de s√©curit√© KB-2025-07."
            return "Action ex√©cut√©e."
        except Exception:
            return "Action trait√©e."

    def _extract_suggested_actions(self, text: str) -> List[str]:
        try:
            actions = []
            for key in ["scan", "audit", "configuration", "formation", "support"]:
                if key in text.lower():
                    actions.append(key)
            return actions[:5] or ["continuer"]
        except Exception:
            return ["continuer"]

    def _extract_follow_up_questions(self, text: str) -> List[str]:
        try:
            qs = []
            if len(text) > 60:
                qs.append("Souhaitez-vous plus de d√©tails ?")
            qs.append("Voulez-vous une d√©monstration ?")
            return qs[:3]
        except Exception:
            return ["Voulez-vous une d√©monstration ?"]


# Instance globale du service Conversational AI
conversational_ai_service = ConversationalAIService()