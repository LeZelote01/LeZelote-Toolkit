"""
Cyber AI - IA sp√©cialis√©e cybers√©curit√© CyberSec Toolkit Pro 2025 PORTABLE
Sprint 1.5 - Intelligence artificielle d√©di√©e aux analyses de s√©curit√© avanc√©es
"""
import asyncio
import json
import uuid
import numpy as np
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union
from fastapi import HTTPException
from pydantic import BaseModel, Field

# Int√©gration Emergent LLM
try:
    from emergentintegrations import EmergentLLM
except ImportError:
    print("‚ö†Ô∏è EmergentLLM non disponible pour Cyber AI - Mode fallback activ√©")
    EmergentLLM = None

from backend.config import settings
from backend.database import get_collection

# Mod√®les de donn√©es Cyber AI
class ThreatAnalysisRequest(BaseModel):
    target: str = Field(..., description="Cible √† analyser (IP, domaine, fichier, etc.)")
    analysis_type: str = Field(..., description="Type d'analyse: network, malware, behavioral, code")
    context: Optional[Dict[str, Any]] = Field(None, description="Contexte suppl√©mentaire")
    severity_threshold: Optional[str] = Field("medium", description="Seuil de s√©v√©rit√©: low, medium, high, critical")

class VulnerabilityPrediction(BaseModel):
    vulnerability_score: float = Field(..., description="Score de vuln√©rabilit√© (0-100)")
    risk_level: str = Field(..., description="Niveau de risque: low, medium, high, critical")
    attack_vectors: List[str] = Field(..., description="Vecteurs d'attaque potentiels")
    mitigation_priority: int = Field(..., description="Priorit√© de rem√©diation (1-10)")
    predicted_exploitability: float = Field(..., description="Probabilit√© d'exploitation (0-1)")

class CyberAIAnalysisResult(BaseModel):
    target: str = Field(..., description="Cible analys√©e")
    analysis_type: str = Field(..., description="Type d'analyse effectu√©e")
    timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    threat_score: float = Field(..., description="Score de menace global (0-100)")
    confidence_level: float = Field(..., description="Niveau de confiance de l'analyse (0-1)")
    vulnerabilities: List[VulnerabilityPrediction] = Field(..., description="Vuln√©rabilit√©s identifi√©es")
    recommendations: List[str] = Field(..., description="Recommandations de s√©curit√©")
    technical_details: Dict[str, Any] = Field(..., description="D√©tails techniques de l'analyse")
    ai_insights: str = Field(..., description="Analyse IA contextuelle")

class AttackSimulationRequest(BaseModel):
    attack_type: str = Field(..., description="Type d'attaque: phishing, malware, apt, insider_threat")
    target_profile: Dict[str, Any] = Field(..., description="Profil de la cible")
    scenario_parameters: Optional[Dict[str, Any]] = Field(None, description="Param√®tres du sc√©nario")

class CyberAIService:
    """Service IA Cybers√©curit√© - Analyses avanc√©es et pr√©dictions"""
    
    def __init__(self):
        self.llm_client = None
        self.threat_database = self._initialize_threat_database()
        self.attack_patterns = self._load_attack_patterns()
        self.vulnerability_models = self._load_vulnerability_models()
        self._initialize_llm()
    
    def _initialize_llm(self):
        """Initialise le client LLM pour Cyber AI"""
        try:
            if EmergentLLM and settings.emergent_llm_key:
                self.llm_client = EmergentLLM(
                    api_key=settings.emergent_llm_key,
                    default_provider=settings.default_llm_provider,
                    default_model=settings.default_llm_model
                )
                print("‚úÖ Cyber AI initialis√© avec Emergent LLM")
            else:
                print("‚ö†Ô∏è Cyber AI - Mode simulation activ√©")
        except Exception as e:
            print(f"‚ùå Erreur initialisation Cyber AI LLM: {e}")
    
    def _initialize_threat_database(self) -> Dict[str, Any]:
        """Initialise la base de donn√©es des menaces"""
        return {
            "malware_families": {
                "ransomware": ["lockbit", "conti", "ryuk", "maze", "sodinokibi"],
                "trojan": ["emotet", "trickbot", "dridex", "icedid", "qakbot"],
                "apt_groups": ["apt1", "apt28", "apt29", "lazarus", "carbanak"]
            },
            "attack_techniques": {
                "mitre_tactics": [
                    "initial_access", "execution", "persistence", "privilege_escalation",
                    "defense_evasion", "credential_access", "discovery", "lateral_movement",
                    "collection", "command_control", "exfiltration", "impact"
                ],
                "common_techniques": [
                    "T1566.001", "T1059.001", "T1055", "T1003", "T1078", "T1083", "T1021.001"
                ]
            },
            "vulnerability_patterns": {
                "owasp_top10": ["injection", "broken_auth", "sensitive_exposure", "xxe", "broken_access"],
                "cve_categories": ["buffer_overflow", "sql_injection", "xss", "privilege_escalation", "rce"]
            }
        }
    
    def _load_attack_patterns(self) -> Dict[str, Any]:
        """Charge les mod√®les de patterns d'attaque"""
        return {
            "phishing_indicators": [
                "suspicious_domains", "url_shorteners", "spelling_errors", "urgency_language", "brand_impersonation"
            ],
            "malware_signatures": [
                "file_entropy", "pe_sections", "api_calls", "network_behavior", "registry_modifications"
            ],
            "network_anomalies": [
                "traffic_spikes", "unusual_ports", "dns_tunneling", "beaconing", "lateral_movement"
            ]
        }
    
    def _load_vulnerability_models(self) -> Dict[str, Any]:
        """Charge les mod√®les de pr√©diction de vuln√©rabilit√©s"""
        return {
            "cvss_weights": {
                "attack_vector": 0.3, "attack_complexity": 0.2,
                "privileges_required": 0.2, "user_interaction": 0.1,
                "scope": 0.1, "impact": 0.1
            },
            "exploitability_factors": [
                "public_exploit_available", "metasploit_module", "known_attacks",
                "vendor_patch_available", "attack_complexity_low"
            ]
        }
    
    async def analyze_threat(self, request: ThreatAnalysisRequest) -> CyberAIAnalysisResult:
        """Analyse approfondie de menace avec IA"""
        try:
            print(f"üß† Cyber AI - Analyse de {request.target} (type: {request.analysis_type})")
            
            # Analyse selon le type
            if request.analysis_type == "network":
                analysis_result = await self._analyze_network_threat(request)
            elif request.analysis_type == "malware":
                analysis_result = await self._analyze_malware_threat(request)
            elif request.analysis_type == "behavioral":
                analysis_result = await self._analyze_behavioral_threat(request)
            elif request.analysis_type == "code":
                analysis_result = await self._analyze_code_security(request)
            else:
                analysis_result = await self._analyze_generic_threat(request)
            
            # Enrichissement avec IA
            ai_insights = await self._generate_ai_insights(request, analysis_result)
            
            # Sauvegarder l'analyse
            await self._save_analysis(request.target, analysis_result)
            
            return CyberAIAnalysisResult(
                target=request.target,
                analysis_type=request.analysis_type,
                threat_score=analysis_result["threat_score"],
                confidence_level=analysis_result["confidence_level"],
                vulnerabilities=analysis_result["vulnerabilities"],
                recommendations=analysis_result["recommendations"],
                technical_details=analysis_result["technical_details"],
                ai_insights=ai_insights
            )
            
        except Exception as e:
            print(f"‚ùå Erreur analyse Cyber AI: {e}")
            raise HTTPException(status_code=500, detail=f"Erreur analyse cyber AI: {str(e)}")
    
    async def _analyze_network_threat(self, request: ThreatAnalysisRequest) -> Dict[str, Any]:
        """Analyse des menaces r√©seau"""
        # Simulation d'analyse r√©seau avanc√©e
        threat_indicators = self._calculate_network_threat_indicators(request.target)
        
        vulnerabilities = []
        recommendations = []
        
        # Analyse des ports ouverts (simulation)
        open_ports = [22, 80, 443, 8080]  # Simulation
        for port in open_ports:
            vuln_score = self._calculate_port_vulnerability_score(port)
            if vuln_score > 30:
                vulnerability = VulnerabilityPrediction(
                    vulnerability_score=vuln_score,
                    risk_level=self._get_risk_level(vuln_score),
                    attack_vectors=[f"port_{port}_exploitation", "service_enumeration"],
                    mitigation_priority=self._calculate_mitigation_priority(vuln_score),
                    predicted_exploitability=vuln_score / 100
                )
                vulnerabilities.append(vulnerability)
                
                if port == 22:
                    recommendations.append("S√©curiser SSH: cl√©s au lieu de mots de passe, fail2ban")
                elif port == 80:
                    recommendations.append("Rediriger HTTP vers HTTPS, d√©sactiver si non n√©cessaire")
        
        return {
            "threat_score": threat_indicators["overall_score"],
            "confidence_level": 0.85,
            "vulnerabilities": vulnerabilities,
            "recommendations": recommendations,
            "technical_details": {
                "scan_method": "nmap_stealth",
                "ports_analyzed": open_ports,
                "threat_indicators": threat_indicators,
                "geolocation_risk": "medium"
            }
        }
    
    async def _analyze_malware_threat(self, request: ThreatAnalysisRequest) -> Dict[str, Any]:
        """Analyse des menaces malware"""
        # Simulation d'analyse malware avanc√©e
        file_hash = request.target  # Supposons que target est un hash de fichier
        
        malware_indicators = {
            "entropy": 7.8,  # Haute entropie = potentiel packing
            "suspicious_apis": ["WriteProcessMemory", "CreateRemoteThread", "VirtualAllocEx"],
            "network_connections": 5,
            "registry_modifications": True,
            "packer_detected": "UPX"
        }
        
        # Score de menace bas√© sur les indicateurs
        threat_score = self._calculate_malware_threat_score(malware_indicators)
        
        vulnerabilities = [
            VulnerabilityPrediction(
                vulnerability_score=threat_score,
                risk_level=self._get_risk_level(threat_score),
                attack_vectors=["process_injection", "persistence_mechanism", "data_exfiltration"],
                mitigation_priority=9 if threat_score > 80 else 6,
                predicted_exploitability=0.9 if threat_score > 80 else 0.6
            )
        ]
        
        recommendations = [
            "Isoler le fichier en quarantaine",
            "Analyser en environnement sandbox",
            "V√©rifier les IOCs sur le r√©seau",
            "Mettre √† jour les signatures antivirus"
        ]
        
        return {
            "threat_score": threat_score,
            "confidence_level": 0.92,
            "vulnerabilities": vulnerabilities,
            "recommendations": recommendations,
            "technical_details": {
                "file_hash": file_hash,
                "malware_family": "trojan.generic" if threat_score > 70 else "suspicious",
                "indicators": malware_indicators,
                "yara_matches": ["suspicious_api_calls", "high_entropy"]
            }
        }
    
    async def _analyze_behavioral_threat(self, request: ThreatAnalysisRequest) -> Dict[str, Any]:
        """Analyse comportementale des menaces"""
        behavioral_patterns = {
            "login_anomalies": True,
            "data_access_patterns": "suspicious",
            "time_based_analysis": "after_hours_activity",
            "geolocation_changes": True,
            "privilege_escalation_attempts": 3
        }
        
        threat_score = self._calculate_behavioral_threat_score(behavioral_patterns)
        
        vulnerabilities = [
            VulnerabilityPrediction(
                vulnerability_score=threat_score,
                risk_level=self._get_risk_level(threat_score),
                attack_vectors=["insider_threat", "account_compromise", "privilege_abuse"],
                mitigation_priority=8,
                predicted_exploitability=0.7
            )
        ]
        
        recommendations = [
            "Renforcer la surveillance utilisateur",
            "Impl√©menter l'authentification multi-facteurs",
            "R√©viser les permissions d'acc√®s",
            "Activer l'audit d√©taill√©"
        ]
        
        return {
            "threat_score": threat_score,
            "confidence_level": 0.78,
            "vulnerabilities": vulnerabilities,
            "recommendations": recommendations,
            "technical_details": {
                "analysis_period": "30_days",
                "behavioral_patterns": behavioral_patterns,
                "risk_indicators": ["anomalous_access", "suspicious_timing"]
            }
        }
    
    async def _analyze_code_security(self, request: ThreatAnalysisRequest) -> Dict[str, Any]:
        """Analyse de s√©curit√© du code"""
        # Simulation d'analyse statique de code
        code_vulnerabilities = {
            "sql_injection": 2,
            "xss_vulnerabilities": 3,
            "hardcoded_credentials": 1,
            "insecure_crypto": 1,
            "path_traversal": 1
        }
        
        threat_score = sum(code_vulnerabilities.values()) * 12  # Score approximatif
        
        vulnerabilities = []
        recommendations = []
        
        for vuln_type, count in code_vulnerabilities.items():
            if count > 0:
                vuln_score = count * 20
                vulnerability = VulnerabilityPrediction(
                    vulnerability_score=vuln_score,
                    risk_level=self._get_risk_level(vuln_score),
                    attack_vectors=[vuln_type, "code_exploitation"],
                    mitigation_priority=8 if vuln_type in ["sql_injection", "xss_vulnerabilities"] else 6,
                    predicted_exploitability=0.8 if vuln_type == "sql_injection" else 0.6
                )
                vulnerabilities.append(vulnerability)
                
                # Recommandations sp√©cifiques
                if vuln_type == "sql_injection":
                    recommendations.append("Utiliser des requ√™tes pr√©par√©es/param√©tr√©es")
                elif vuln_type == "xss_vulnerabilities":
                    recommendations.append("Impl√©menter l'√©chappement des donn√©es utilisateur")
                elif vuln_type == "hardcoded_credentials":
                    recommendations.append("Externaliser les credentials dans des variables d'environnement")
        
        return {
            "threat_score": min(threat_score, 100),
            "confidence_level": 0.88,
            "vulnerabilities": vulnerabilities,
            "recommendations": recommendations,
            "technical_details": {
                "scan_type": "static_analysis",
                "vulnerabilities_found": code_vulnerabilities,
                "lines_analyzed": 15000,
                "security_rules": "owasp_top10"
            }
        }
    
    async def _analyze_generic_threat(self, request: ThreatAnalysisRequest) -> Dict[str, Any]:
        """Analyse g√©n√©rique de menace"""
        threat_score = 65.0  # Score par d√©faut
        
        vulnerability = VulnerabilityPrediction(
            vulnerability_score=threat_score,
            risk_level=self._get_risk_level(threat_score),
            attack_vectors=["generic_attack"],
            mitigation_priority=5,
            predicted_exploitability=0.5
        )
        
        return {
            "threat_score": threat_score,
            "confidence_level": 0.65,
            "vulnerabilities": [vulnerability],
            "recommendations": ["Effectuer une analyse plus sp√©cifique", "Surveiller l'activit√©"],
            "technical_details": {"analysis_type": "generic", "target": request.target}
        }
    
    def _calculate_network_threat_indicators(self, target: str) -> Dict[str, Any]:
        """Calcule les indicateurs de menace r√©seau"""
        # Simulation bas√©e sur le target
        base_score = len(target) % 50 + 30
        
        return {
            "overall_score": base_score,
            "open_ports_risk": base_score * 0.3,
            "service_versions_risk": base_score * 0.2,
            "configuration_risk": base_score * 0.5
        }
    
    def _calculate_port_vulnerability_score(self, port: int) -> float:
        """Calcule le score de vuln√©rabilit√© d'un port"""
        # Ports √† haut risque
        high_risk_ports = {22: 40, 23: 80, 21: 70, 3389: 60}
        medium_risk_ports = {80: 30, 443: 20, 8080: 35}
        
        if port in high_risk_ports:
            return high_risk_ports[port]
        elif port in medium_risk_ports:
            return medium_risk_ports[port]
        else:
            return 15  # Score de base pour les autres ports
    
    def _calculate_malware_threat_score(self, indicators: Dict[str, Any]) -> float:
        """Calcule le score de menace malware"""
        score = 0
        
        # Entropie √©lev√©e
        if indicators.get("entropy", 0) > 7:
            score += 30
        
        # APIs suspectes
        score += len(indicators.get("suspicious_apis", [])) * 15
        
        # Connexions r√©seau
        score += indicators.get("network_connections", 0) * 5
        
        # Modifications registre
        if indicators.get("registry_modifications"):
            score += 20
        
        # Packer d√©tect√©
        if indicators.get("packer_detected"):
            score += 25
        
        return min(score, 100)
    
    def _calculate_behavioral_threat_score(self, patterns: Dict[str, Any]) -> float:
        """Calcule le score de menace comportementale"""
        score = 0
        
        if patterns.get("login_anomalies"):
            score += 25
        
        if patterns.get("data_access_patterns") == "suspicious":
            score += 30
        
        if patterns.get("geolocation_changes"):
            score += 20
        
        score += patterns.get("privilege_escalation_attempts", 0) * 10
        
        return min(score, 100)
    
    def _get_risk_level(self, score: float) -> str:
        """D√©termine le niveau de risque selon le score"""
        if score >= 80:
            return "critical"
        elif score >= 60:
            return "high"
        elif score >= 40:
            return "medium"
        else:
            return "low"
    
    def _calculate_mitigation_priority(self, score: float) -> int:
        """Calcule la priorit√© de rem√©diation"""
        if score >= 80:
            return 10
        elif score >= 60:
            return 8
        elif score >= 40:
            return 6
        else:
            return 4
    
    async def _generate_ai_insights(self, request: ThreatAnalysisRequest, analysis_result: Dict[str, Any]) -> str:
        """G√©n√®re des insights IA contextuels"""
        if self.llm_client:
            return await self._generate_llm_insights(request, analysis_result)
        else:
            return self._generate_fallback_insights(request, analysis_result)
    
    async def _generate_llm_insights(self, request: ThreatAnalysisRequest, analysis_result: Dict[str, Any]) -> str:
        """G√©n√®re des insights via LLM"""
        try:
            prompt = f"""En tant qu'expert cybers√©curit√© senior, analysez ces r√©sultats d'analyse de menace:

Cible: {request.target}
Type d'analyse: {request.analysis_type}
Score de menace: {analysis_result['threat_score']}/100
Niveau de confiance: {analysis_result['confidence_level']}

Fournissez une analyse experte incluant:
1. √âvaluation du niveau de risque
2. Contexte de la menace dans l'√©cosyst√®me actuel
3. Priorit√©s d'action imm√©diate
4. Strat√©gies de rem√©diation √† long terme
5. Indicateurs de surveillance continue

R√©ponse concise et actionnable pour un RSSI."""

            messages = [
                {"role": "system", "content": "Tu es un expert cybers√©curit√© senior sp√©cialis√© dans l'analyse de menaces."},
                {"role": "user", "content": prompt}
            ]
            
            response = await asyncio.to_thread(
                self.llm_client.chat.completions.create,
                model=settings.default_llm_model,
                messages=messages,
                max_tokens=1500,
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur insights LLM: {e}")
            return self._generate_fallback_insights(request, analysis_result)
    
    def _generate_fallback_insights(self, request: ThreatAnalysisRequest, analysis_result: Dict[str, Any]) -> str:
        """G√©n√®re des insights de fallback"""
        threat_score = analysis_result['threat_score']
        analysis_type = request.analysis_type
        
        if threat_score >= 80:
            urgency = "üö® **CRITIQUE - ACTION IMM√âDIATE REQUISE**"
            priority = "Priorit√© maximale"
        elif threat_score >= 60:
            urgency = "‚ö†Ô∏è **√âLEV√â - Action rapide recommand√©e**"
            priority = "Priorit√© √©lev√©e"
        elif threat_score >= 40:
            urgency = "üìã **MOYEN - Surveillance renforc√©e**"
            priority = "Priorit√© mod√©r√©e"
        else:
            urgency = "‚ÑπÔ∏è **FAIBLE - Surveillance standard**"
            priority = "Priorit√© faible"
        
        insights = f"""## {urgency}

### üéØ √âvaluation Cyber AI

**Score de menace:** {threat_score}/100 ({self._get_risk_level(threat_score).upper()})
**Type d'analyse:** {analysis_type.title()}
**Priorit√©:** {priority}

### üìä Contexte de la menace
Bas√© sur l'analyse {analysis_type}, la cible pr√©sente {'un risque significatif' if threat_score > 60 else 'un niveau de risque mod√©r√©'} n√©cessitant {'une intervention imm√©diate' if threat_score > 80 else 'une surveillance appropri√©e'}.

### ‚ö° Actions recommand√©es
1. **Imm√©diat:** {'Isolation et containment' if threat_score > 80 else 'Analyse approfondie'}
2. **Court terme:** Impl√©mentation des recommandations de s√©curit√©
3. **Long terme:** Surveillance continue et am√©lioration de la posture

### üîç Surveillance continue
- Monitoring des indicateurs identifi√©s
- R√©vision p√©riodique des mesures de s√©curit√©
- Mise √† jour des r√®gles de d√©tection

*Analyse g√©n√©r√©e par Cyber AI v1.0 - CyberSec Toolkit Pro 2025*"""
        
        return insights
    
    async def simulate_attack(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simule un sc√©nario d'attaque pour √©valuer la r√©sistance"""
        try:
            print(f"üéØ Cyber AI - Simulation d'attaque {request.attack_type}")
            
            # Simuler selon le type d'attaque
            if request.attack_type == "phishing":
                simulation_result = await self._simulate_phishing_attack(request)
            elif request.attack_type == "malware":
                simulation_result = await self._simulate_malware_attack(request)
            elif request.attack_type == "apt":
                simulation_result = await self._simulate_apt_attack(request)
            elif request.attack_type == "insider_threat":
                simulation_result = await self._simulate_insider_threat(request)
            else:
                simulation_result = await self._simulate_generic_attack(request)
            
            return simulation_result
            
        except Exception as e:
            print(f"‚ùå Erreur simulation attaque: {e}")
            raise HTTPException(status_code=500, detail=f"Erreur simulation: {str(e)}")
    
    async def _simulate_phishing_attack(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simule une attaque de phishing"""
        success_probability = 0.3  # 30% de base
        
        # Ajustements bas√©s sur le profil cible
        profile = request.target_profile
        if profile.get("security_awareness_training", False):
            success_probability *= 0.5
        
        if profile.get("email_filtering", "basic") == "advanced":
            success_probability *= 0.3
        
        return {
            "attack_type": "phishing",
            "success_probability": success_probability,
            "impact_assessment": "medium" if success_probability > 0.2 else "low",
            "countermeasures_effectiveness": 1 - success_probability,
            "recommendations": [
                "Am√©liorer la formation de sensibilisation",
                "Renforcer le filtrage email",
                "Impl√©menter DMARC/SPF/DKIM",
                "Tests de phishing r√©guliers"
            ]
        }
    
    async def _simulate_malware_attack(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simule une attaque malware"""
        success_probability = 0.4
        
        profile = request.target_profile
        if profile.get("antivirus_protection", "basic") == "advanced":
            success_probability *= 0.2
        
        if profile.get("endpoint_detection", False):
            success_probability *= 0.3
        
        return {
            "attack_type": "malware",
            "success_probability": success_probability,
            "impact_assessment": "high" if success_probability > 0.3 else "medium",
            "countermeasures_effectiveness": 1 - success_probability,
            "recommendations": [
                "D√©ployer EDR/XDR avanc√©",
                "Renforcer l'isolation r√©seau",
                "Backup et recovery test√©s",
                "Sandboxing des fichiers suspects"
            ]
        }
    
    async def _simulate_apt_attack(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simule une attaque APT"""
        return {
            "attack_type": "apt",
            "success_probability": 0.6,  # APT sont g√©n√©ralement sophistiqu√©es
            "impact_assessment": "critical",
            "countermeasures_effectiveness": 0.4,
            "recommendations": [
                "Threat hunting proactif",
                "Segmentation r√©seau avanc√©e",
                "Monitoring comportemental",
                "Intelligence sur les menaces"
            ]
        }
    
    async def _simulate_insider_threat(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simule une menace interne"""
        return {
            "attack_type": "insider_threat",
            "success_probability": 0.5,
            "impact_assessment": "high",
            "countermeasures_effectiveness": 0.5,
            "recommendations": [
                "Principe du moindre privil√®ge",
                "Surveillance des acc√®s privil√©gi√©s",
                "Analyse comportementale",
                "Contr√¥les d'int√©grit√© des donn√©es"
            ]
        }
    
    async def _simulate_generic_attack(self, request: AttackSimulationRequest) -> Dict[str, Any]:
        """Simulation g√©n√©rique"""
        return {
            "attack_type": request.attack_type,
            "success_probability": 0.4,
            "impact_assessment": "medium",
            "countermeasures_effectiveness": 0.6,
            "recommendations": ["√âvaluation sp√©cialis√©e recommand√©e"]
        }
    
    async def _save_analysis(self, target: str, analysis_result: Dict[str, Any]):
        """Sauvegarde l'analyse en base"""
        try:
            cyber_analyses = await get_collection("cyber_ai_analyses")
            
            document = {
                "_id": str(uuid.uuid4()),
                "target": target,
                "analysis_result": analysis_result,
                "created_at": datetime.now(timezone.utc),
                "service": "cyber_ai"
            }
            
            await cyber_analyses.insert_one(document)
            print(f"‚úÖ Analyse Cyber AI sauvegard√©e pour {target}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde analyse Cyber AI: {e}")
    
    async def get_threat_trends(self, days: int = 30) -> Dict[str, Any]:
        """R√©cup√®re les tendances de menaces"""
        try:
            cyber_analyses = await get_collection("cyber_ai_analyses")
            
            # R√©cup√©rer les analyses r√©centes
            from datetime import timedelta
            since_date = datetime.now(timezone.utc) - timedelta(days=days)
            
            recent_analyses = await cyber_analyses.find({
                "created_at": {"$gte": since_date}
            }).to_list(length=100)
            
            # Analyser les tendances
            if recent_analyses:
                avg_threat_score = sum(a["analysis_result"]["threat_score"] for a in recent_analyses) / len(recent_analyses)
                threat_types = {}
                
                for analysis in recent_analyses:
                    for vuln in analysis["analysis_result"].get("vulnerabilities", []):
                        for vector in vuln.attack_vectors:
                            threat_types[vector] = threat_types.get(vector, 0) + 1
                
                return {
                    "period_days": days,
                    "total_analyses": len(recent_analyses),
                    "average_threat_score": round(avg_threat_score, 2),
                    "common_attack_vectors": sorted(threat_types.items(), key=lambda x: x[1], reverse=True)[:10],
                    "trend": "increasing" if avg_threat_score > 60 else "stable"
                }
            
            return {
                "period_days": days,
                "total_analyses": 0,
                "message": "Pas assez de donn√©es pour analyser les tendances"
            }
            
        except Exception as e:
            print(f"‚ùå Erreur r√©cup√©ration tendances: {e}")
            return {"error": str(e)}

# Instance globale du service Cyber AI
cyber_ai_service = CyberAIService()